# Web3è¯­ä¹‰çŸ¥è¯†ç³»ç»Ÿå®æ–½è„šæœ¬ / Web3 Semantics Knowledge System Implementation Scripts

## æ¦‚è¿° / Overview

æœ¬æ–‡æ¡£æä¾›å…·ä½“çš„å®æ–½è„šæœ¬ï¼Œç”¨äºæ¨è¿›Web3è¯­ä¹‰çŸ¥è¯†ç³»ç»ŸæŠ€æœ¯å¹³å°çš„å¼€å‘ã€‚åŒ…æ‹¬ç¯å¢ƒæ­å»ºã€ä»£ç ç”Ÿæˆã€æµ‹è¯•éƒ¨ç½²ç­‰è‡ªåŠ¨åŒ–è„šæœ¬ã€‚

This document provides specific implementation scripts for advancing the development of the Web3 semantics knowledge system technical platform. Including environment setup, code generation, testing deployment and other automated scripts.

## 1. å¼€å‘ç¯å¢ƒæ­å»ºè„šæœ¬ / Development Environment Setup Scripts

### 1.1 é¡¹ç›®åˆå§‹åŒ–è„šæœ¬

```bash
#!/bin/bash
# Web3è¯­ä¹‰çŸ¥è¯†ç³»ç»Ÿé¡¹ç›®åˆå§‹åŒ–è„šæœ¬
# Web3 Semantics Knowledge System Project Initialization Script

echo "ğŸš€ å¼€å§‹åˆå§‹åŒ–Web3è¯­ä¹‰çŸ¥è¯†ç³»ç»Ÿé¡¹ç›®..."
echo "ğŸš€ Starting Web3 Semantics Knowledge System Project Initialization..."

# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
mkdir -p web3-semantics-platform/{frontend,backend,infrastructure,docs,tests}
mkdir -p web3-semantics-platform/backend/{services,models,controllers,utils}
mkdir -p web3-semantics-platform/frontend/{src,public,components,pages}
mkdir -p web3-semantics-platform/infrastructure/{docker,kubernetes,monitoring}

# åˆå§‹åŒ–Gitä»“åº“
cd web3-semantics-platform
git init
git add .
git commit -m "Initial commit: Web3 Semantics Knowledge System Platform"

# åˆ›å»ºDockerç¯å¢ƒ
cat > docker-compose.yml << 'EOF'
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: web3_semantics
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  elasticsearch:
    image: elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  neo4j:
    image: neo4j:5.8
    environment:
      NEO4J_AUTH: neo4j/password
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data

volumes:
  postgres_data:
  redis_data:
  elasticsearch_data:
  neo4j_data:
EOF

echo "âœ… é¡¹ç›®ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ"
echo "âœ… Project directory structure created successfully"
```

### 1.2 åç«¯æœåŠ¡åˆå§‹åŒ–è„šæœ¬

```bash
#!/bin/bash
# åç«¯æœåŠ¡åˆå§‹åŒ–è„šæœ¬
# Backend Service Initialization Script

echo "ğŸ”§ åˆå§‹åŒ–åç«¯æœåŠ¡..."
echo "ğŸ”§ Initializing backend services..."

# åˆ›å»ºRusté¡¹ç›®
cd backend
cargo new web3-semantics-api
cd web3-semantics-api

# æ›´æ–°Cargo.toml
cat > Cargo.toml << 'EOF'
[package]
name = "web3-semantics-api"
version = "0.1.0"
edition = "2021"

[dependencies]
actix-web = "4.3"
actix-rt = "2.8"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tokio = { version = "1.0", features = ["full"] }
sqlx = { version = "0.6", features = ["runtime-tokio-rustls", "postgres"] }
redis = { version = "0.23", features = ["tokio-comp"] }
elasticsearch = "8.8"
neo4rs = "0.6"
uuid = { version = "1.0", features = ["v4"] }
chrono = { version = "0.4", features = ["serde"] }
log = "0.4"
env_logger = "0.10"
dotenv = "0.15"
anyhow = "1.0"
thiserror = "1.0"
validator = { version = "0.16", features = ["derive"] }
bcrypt = "0.15"
jsonwebtoken = "8.3"
reqwest = { version = "0.11", features = ["json"] }
futures = "0.3"
async-trait = "0.1"
tracing = "0.1"
tracing-subscriber = "0.3"
EOF

# åˆ›å»ºåŸºç¡€æœåŠ¡ç»“æ„
mkdir -p src/{services,models,controllers,utils,middleware}
mkdir -p src/services/{user,content,search,analytics}

echo "âœ… åç«¯æœåŠ¡åˆå§‹åŒ–å®Œæˆ"
echo "âœ… Backend service initialization completed"
```

### 1.3 å‰ç«¯åº”ç”¨åˆå§‹åŒ–è„šæœ¬

```bash
#!/bin/bash
# å‰ç«¯åº”ç”¨åˆå§‹åŒ–è„šæœ¬
# Frontend Application Initialization Script

echo "ğŸ¨ åˆå§‹åŒ–å‰ç«¯åº”ç”¨..."
echo "ğŸ¨ Initializing frontend application..."

# åˆ›å»ºReactåº”ç”¨
cd ../frontend
npx create-react-app web3-semantics-ui --template typescript
cd web3-semantics-ui

# å®‰è£…ä¾èµ–
npm install @mui/material @emotion/react @emotion/styled
npm install @mui/icons-material @mui/lab
npm install @reduxjs/toolkit react-redux
npm install react-router-dom
npm install axios
npm install d3 @types/d3
npm install recharts
npm install @types/node

# åˆ›å»ºåº”ç”¨ç»“æ„
mkdir -p src/{components,pages,services,store,utils,hooks}
mkdir -p src/components/{common,layout,forms,charts}
mkdir -p src/pages/{home,dashboard,knowledge,search,profile}

echo "âœ… å‰ç«¯åº”ç”¨åˆå§‹åŒ–å®Œæˆ"
echo "âœ… Frontend application initialization completed"
```

## 2. æ ¸å¿ƒæœåŠ¡å®ç°è„šæœ¬ / Core Service Implementation Scripts

### 2.1 ç”¨æˆ·æœåŠ¡å®ç°

```rust
// src/services/user/user_service.rs
use actix_web::{web, HttpResponse, Result};
use serde::{Deserialize, Serialize};
use sqlx::PgPool;
use uuid::Uuid;
use chrono::{DateTime, Utc};

#[derive(Debug, Serialize, Deserialize)]
pub struct User {
    pub id: Uuid,
    pub username: String,
    pub email: String,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

#[derive(Debug, Deserialize)]
pub struct CreateUserRequest {
    pub username: String,
    pub email: String,
    pub password: String,
}

pub struct UserService {
    pool: PgPool,
}

impl UserService {
    pub fn new(pool: PgPool) -> Self {
        Self { pool }
    }

    pub async fn create_user(&self, request: CreateUserRequest) -> Result<User, sqlx::Error> {
        let user_id = Uuid::new_v4();
        let hashed_password = bcrypt::hash(request.password.as_bytes(), bcrypt::DEFAULT_COST)?;
        
        let user = sqlx::query_as!(
            User,
            r#"
            INSERT INTO users (id, username, email, password_hash, created_at, updated_at)
            VALUES ($1, $2, $3, $4, $5, $5)
            RETURNING id, username, email, created_at, updated_at
            "#,
            user_id,
            request.username,
            request.email,
            hashed_password,
            Utc::now()
        )
        .fetch_one(&self.pool)
        .await?;

        Ok(user)
    }

    pub async fn get_user_by_id(&self, user_id: Uuid) -> Result<Option<User>, sqlx::Error> {
        let user = sqlx::query_as!(
            User,
            r#"
            SELECT id, username, email, created_at, updated_at
            FROM users
            WHERE id = $1
            "#,
            user_id
        )
        .fetch_optional(&self.pool)
        .await?;

        Ok(user)
    }

    pub async fn update_user(&self, user_id: Uuid, updates: UserUpdates) -> Result<User, sqlx::Error> {
        let user = sqlx::query_as!(
            User,
            r#"
            UPDATE users
            SET username = COALESCE($2, username),
                email = COALESCE($3, email),
                updated_at = $4
            WHERE id = $1
            RETURNING id, username, email, created_at, updated_at
            "#,
            user_id,
            updates.username,
            updates.email,
            Utc::now()
        )
        .fetch_one(&self.pool)
        .await?;

        Ok(user)
    }
}

#[derive(Debug, Deserialize)]
pub struct UserUpdates {
    pub username: Option<String>,
    pub email: Option<String>,
}
```

### 2.2 å†…å®¹ç®¡ç†æœåŠ¡å®ç°

```rust
// src/services/content/content_service.rs
use actix_web::{web, HttpResponse, Result};
use serde::{Deserialize, Serialize};
use sqlx::PgPool;
use uuid::Uuid;
use chrono::{DateTime, Utc};

#[derive(Debug, Serialize, Deserialize)]
pub struct Content {
    pub id: Uuid,
    pub title: String,
    pub content: String,
    pub content_type: String,
    pub author_id: Uuid,
    pub status: String,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

#[derive(Debug, Deserialize)]
pub struct CreateContentRequest {
    pub title: String,
    pub content: String,
    pub content_type: String,
    pub author_id: Uuid,
}

pub struct ContentService {
    pool: PgPool,
}

impl ContentService {
    pub fn new(pool: PgPool) -> Self {
        Self { pool }
    }

    pub async fn create_content(&self, request: CreateContentRequest) -> Result<Content, sqlx::Error> {
        let content_id = Uuid::new_v4();
        
        let content = sqlx::query_as!(
            Content,
            r#"
            INSERT INTO contents (id, title, content, content_type, author_id, status, created_at, updated_at)
            VALUES ($1, $2, $3, $4, $5, 'draft', $6, $6)
            RETURNING id, title, content, content_type, author_id, status, created_at, updated_at
            "#,
            content_id,
            request.title,
            request.content,
            request.content_type,
            request.author_id,
            Utc::now()
        )
        .fetch_one(&self.pool)
        .await?;

        Ok(content)
    }

    pub async fn get_content_by_id(&self, content_id: Uuid) -> Result<Option<Content>, sqlx::Error> {
        let content = sqlx::query_as!(
            Content,
            r#"
            SELECT id, title, content, content_type, author_id, status, created_at, updated_at
            FROM contents
            WHERE id = $1
            "#,
            content_id
        )
        .fetch_optional(&self.pool)
        .await?;

        Ok(content)
    }

    pub async fn search_contents(&self, query: &str) -> Result<Vec<Content>, sqlx::Error> {
        let contents = sqlx::query_as!(
            Content,
            r#"
            SELECT id, title, content, content_type, author_id, status, created_at, updated_at
            FROM contents
            WHERE title ILIKE $1 OR content ILIKE $1
            ORDER BY created_at DESC
            "#,
            format!("%{}%", query)
        )
        .fetch_all(&self.pool)
        .await?;

        Ok(contents)
    }

    pub async fn update_content(&self, content_id: Uuid, updates: ContentUpdates) -> Result<Content, sqlx::Error> {
        let content = sqlx::query_as!(
            Content,
            r#"
            UPDATE contents
            SET title = COALESCE($2, title),
                content = COALESCE($3, content),
                content_type = COALESCE($4, content_type),
                status = COALESCE($5, status),
                updated_at = $6
            WHERE id = $1
            RETURNING id, title, content, content_type, author_id, status, created_at, updated_at
            "#,
            content_id,
            updates.title,
            updates.content,
            updates.content_type,
            updates.status,
            Utc::now()
        )
        .fetch_one(&self.pool)
        .await?;

        Ok(content)
    }
}

#[derive(Debug, Deserialize)]
pub struct ContentUpdates {
    pub title: Option<String>,
    pub content: Option<String>,
    pub content_type: Option<String>,
    pub status: Option<String>,
}
```

### 2.3 æœç´¢æœåŠ¡å®ç°

```rust
// src/services/search/search_service.rs
use actix_web::{web, HttpResponse, Result};
use serde::{Deserialize, Serialize};
use sqlx::PgPool;
use uuid::Uuid;
use elasticsearch::{Elasticsearch, SearchParts};
use serde_json::json;

#[derive(Debug, Serialize, Deserialize)]
pub struct SearchResult {
    pub id: Uuid,
    pub title: String,
    pub content: String,
    pub content_type: String,
    pub score: f64,
    pub highlights: Vec<String>,
}

#[derive(Debug, Deserialize)]
pub struct SearchRequest {
    pub query: String,
    pub content_type: Option<String>,
    pub page: Option<i32>,
    pub size: Option<i32>,
}

pub struct SearchService {
    pool: PgPool,
    elasticsearch: Elasticsearch,
}

impl SearchService {
    pub fn new(pool: PgPool, elasticsearch: Elasticsearch) -> Self {
        Self { pool, elasticsearch }
    }

    pub async fn search(&self, request: SearchRequest) -> Result<Vec<SearchResult>, Box<dyn std::error::Error>> {
        let page = request.page.unwrap_or(1);
        let size = request.size.unwrap_or(10);
        let from = (page - 1) * size;

        let search_body = json!({
            "query": {
                "bool": {
                    "must": [
                        {
                            "multi_match": {
                                "query": request.query,
                                "fields": ["title^2", "content"],
                                "type": "best_fields"
                            }
                        }
                    ],
                    "filter": request.content_type.map(|ct| json!({
                        "term": { "content_type": ct }
                    }))
                }
            },
            "highlight": {
                "fields": {
                    "title": {},
                    "content": {
                        "fragment_size": 150,
                        "number_of_fragments": 3
                    }
                }
            },
            "from": from,
            "size": size
        });

        let response = self.elasticsearch
            .search(SearchParts::Index(&["contents"]))
            .body(search_body)
            .send()
            .await?;

        let search_response: serde_json::Value = response.json().await?;
        
        // è§£ææœç´¢ç»“æœ
        let hits = search_response["hits"]["hits"].as_array().unwrap_or(&vec![]);
        let mut results = Vec::new();

        for hit in hits {
            let source = &hit["_source"];
            let highlights = hit["highlight"].as_object()
                .map(|h| {
                    h.values()
                        .flat_map(|v| v.as_array().unwrap_or(&vec![]))
                        .filter_map(|v| v.as_str())
                        .map(|s| s.to_string())
                        .collect()
                })
                .unwrap_or_else(Vec::new);

            let result = SearchResult {
                id: Uuid::parse_str(hit["_id"].as_str().unwrap_or("")).unwrap_or_default(),
                title: source["title"].as_str().unwrap_or("").to_string(),
                content: source["content"].as_str().unwrap_or("").to_string(),
                content_type: source["content_type"].as_str().unwrap_or("").to_string(),
                score: hit["_score"].as_f64().unwrap_or(0.0),
                highlights,
            };

            results.push(result);
        }

        Ok(results)
    }

    pub async fn index_content(&self, content: &Content) -> Result<(), Box<dyn std::error::Error>> {
        let document = json!({
            "id": content.id.to_string(),
            "title": content.title,
            "content": content.content,
            "content_type": content.content_type,
            "author_id": content.author_id.to_string(),
            "created_at": content.created_at.to_rfc3339(),
            "updated_at": content.updated_at.to_rfc3339(),
        });

        self.elasticsearch
            .index(elasticsearch::IndexParts::IndexId("contents", &content.id.to_string()))
            .body(document)
            .send()
            .await?;

        Ok(())
    }
}
```

## 3. æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ / Database Initialization Scripts

### 3.1 PostgreSQLæ•°æ®åº“åˆå§‹åŒ–

```sql
-- æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
-- Database Initialization Script

-- åˆ›å»ºç”¨æˆ·è¡¨
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºå†…å®¹è¡¨
CREATE TABLE contents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    content_type VARCHAR(50) NOT NULL,
    author_id UUID NOT NULL REFERENCES users(id),
    status VARCHAR(20) DEFAULT 'draft',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºçŸ¥è¯†å›¾è°±èŠ‚ç‚¹è¡¨
CREATE TABLE knowledge_nodes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    node_type VARCHAR(50) NOT NULL,
    properties JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºçŸ¥è¯†å›¾è°±å…³ç³»è¡¨
CREATE TABLE knowledge_relationships (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_node_id UUID NOT NULL REFERENCES knowledge_nodes(id),
    target_node_id UUID NOT NULL REFERENCES knowledge_nodes(id),
    relationship_type VARCHAR(50) NOT NULL,
    properties JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºå­¦ä¹ è·¯å¾„è¡¨
CREATE TABLE learning_paths (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id),
    path_name VARCHAR(255) NOT NULL,
    path_data JSONB NOT NULL,
    progress JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºç”¨æˆ·æ´»åŠ¨è¡¨
CREATE TABLE user_activities (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id),
    activity_type VARCHAR(50) NOT NULL,
    activity_data JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_contents_author_id ON contents(author_id);
CREATE INDEX idx_contents_status ON contents(status);
CREATE INDEX idx_contents_created_at ON contents(created_at);
CREATE INDEX idx_knowledge_nodes_type ON knowledge_nodes(node_type);
CREATE INDEX idx_knowledge_relationships_type ON knowledge_relationships(relationship_type);
CREATE INDEX idx_user_activities_user_id ON user_activities(user_id);
CREATE INDEX idx_user_activities_type ON user_activities(activity_type);
CREATE INDEX idx_user_activities_created_at ON user_activities(created_at);

-- åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX idx_contents_search ON contents USING gin(to_tsvector('english', title || ' ' || content));
```

### 3.2 Redisç¼“å­˜é…ç½®

```bash
#!/bin/bash
# Redisç¼“å­˜é…ç½®è„šæœ¬
# Redis Cache Configuration Script

echo "ğŸ”§ é…ç½®Redisç¼“å­˜..."
echo "ğŸ”§ Configuring Redis cache..."

# åˆ›å»ºRedisé…ç½®æ–‡ä»¶
cat > redis.conf << 'EOF'
# Redisé…ç½®æ–‡ä»¶
# Redis Configuration File

# åŸºæœ¬é…ç½®
port 6379
bind 0.0.0.0
timeout 300
tcp-keepalive 60

# å†…å­˜é…ç½®
maxmemory 256mb
maxmemory-policy allkeys-lru

# æŒä¹…åŒ–é…ç½®
save 900 1
save 300 10
save 60 10000

# æ—¥å¿—é…ç½®
loglevel notice
logfile ""

# å®‰å…¨é…ç½®
requirepass web3semantics2024

# æ€§èƒ½ä¼˜åŒ–
tcp-backlog 511
databases 16
EOF

echo "âœ… Redisç¼“å­˜é…ç½®å®Œæˆ"
echo "âœ… Redis cache configuration completed"
```

## 4. APIè·¯ç”±é…ç½®è„šæœ¬ / API Route Configuration Scripts

### 4.1 ä¸»åº”ç”¨è·¯ç”±é…ç½®

```rust
// src/main.rs
use actix_web::{web, App, HttpServer, middleware};
use sqlx::PgPool;
use elasticsearch::Elasticsearch;

mod services;
mod controllers;
mod models;
mod middleware;
mod utils;

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    env_logger::init_from_env(env_logger::Env::new().default_filter_or("info"));

    // æ•°æ®åº“è¿æ¥
    let database_url = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "postgres://admin:password@localhost:5432/web3_semantics".to_string());
    
    let pool = PgPool::connect(&database_url)
        .await
        .expect("Failed to connect to database");

    // Elasticsearchè¿æ¥
    let elasticsearch_url = std::env::var("ELASTICSEARCH_URL")
        .unwrap_or_else(|_| "http://localhost:9200".to_string());
    
    let elasticsearch = Elasticsearch::new(
        elasticsearch::http::transport::SingleNodeConnection::new(elasticsearch_url)
            .expect("Failed to connect to Elasticsearch")
    );

    // å¯åŠ¨HTTPæœåŠ¡å™¨
    HttpServer::new(move || {
        App::new()
            .wrap(middleware::Logger::default())
            .wrap(middleware::Compress::default())
            .app_data(web::Data::new(pool.clone()))
            .app_data(web::Data::new(elasticsearch.clone()))
            .service(
                web::scope("/api/v1")
                    .configure(controllers::user::configure)
                    .configure(controllers::content::configure)
                    .configure(controllers::search::configure)
                    .configure(controllers::analytics::configure)
            )
    })
    .bind("127.0.0.1:8080")?
    .run()
    .await
}
```

### 4.2 ç”¨æˆ·æ§åˆ¶å™¨é…ç½®

```rust
// src/controllers/user.rs
use actix_web::{web, HttpResponse, Result};
use crate::services::user::UserService;
use crate::models::user::{CreateUserRequest, UserUpdates};

pub fn configure(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/users")
            .route("", web::post().to(create_user))
            .route("/{id}", web::get().to(get_user))
            .route("/{id}", web::put().to(update_user))
            .route("/{id}", web::delete().to(delete_user))
    );
}

async fn create_user(
    pool: web::Data<PgPool>,
    request: web::Json<CreateUserRequest>,
) -> Result<HttpResponse> {
    let user_service = UserService::new(pool.get_ref().clone());
    
    match user_service.create_user(request.into_inner()).await {
        Ok(user) => Ok(HttpResponse::Created().json(user)),
        Err(e) => Ok(HttpResponse::InternalServerError().body(e.to_string())),
    }
}

async fn get_user(
    pool: web::Data<PgPool>,
    path: web::Path<uuid::Uuid>,
) -> Result<HttpResponse> {
    let user_service = UserService::new(pool.get_ref().clone());
    
    match user_service.get_user_by_id(path.into_inner()).await {
        Ok(Some(user)) => Ok(HttpResponse::Ok().json(user)),
        Ok(None) => Ok(HttpResponse::NotFound().body("User not found")),
        Err(e) => Ok(HttpResponse::InternalServerError().body(e.to_string())),
    }
}

async fn update_user(
    pool: web::Data<PgPool>,
    path: web::Path<uuid::Uuid>,
    request: web::Json<UserUpdates>,
) -> Result<HttpResponse> {
    let user_service = UserService::new(pool.get_ref().clone());
    
    match user_service.update_user(path.into_inner(), request.into_inner()).await {
        Ok(user) => Ok(HttpResponse::Ok().json(user)),
        Err(e) => Ok(HttpResponse::InternalServerError().body(e.to_string())),
    }
}

async fn delete_user(
    pool: web::Data<PgPool>,
    path: web::Path<uuid::Uuid>,
) -> Result<HttpResponse> {
    let user_service = UserService::new(pool.get_ref().clone());
    
    match user_service.delete_user(path.into_inner()).await {
        Ok(_) => Ok(HttpResponse::NoContent().finish()),
        Err(e) => Ok(HttpResponse::InternalServerError().body(e.to_string())),
    }
}
```

## 5. å‰ç«¯ç»„ä»¶å®ç°è„šæœ¬ / Frontend Component Implementation Scripts

### 5.1 ä¸»åº”ç”¨ç»„ä»¶

```typescript
// src/App.tsx
import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';
import { Provider } from 'react-redux';
import { store } from './store';

import Layout from './components/layout/Layout';
import Home from './pages/Home';
import Dashboard from './pages/Dashboard';
import Knowledge from './pages/Knowledge';
import Search from './pages/Search';
import Profile from './pages/Profile';

const theme = createTheme({
  palette: {
    mode: 'dark',
    primary: {
      main: '#1976d2',
    },
    secondary: {
      main: '#dc004e',
    },
  },
});

function App() {
  return (
    <Provider store={store}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <Router>
          <Layout>
            <Routes>
              <Route path="/" element={<Home />} />
              <Route path="/dashboard" element={<Dashboard />} />
              <Route path="/knowledge" element={<Knowledge />} />
              <Route path="/search" element={<Search />} />
              <Route path="/profile" element={<Profile />} />
            </Routes>
          </Layout>
        </Router>
      </ThemeProvider>
    </Provider>
  );
}

export default App;
```

### 5.2 çŸ¥è¯†å›¾è°±å¯è§†åŒ–ç»„ä»¶

```typescript
// src/components/KnowledgeGraph.tsx
import React, { useEffect, useRef } from 'react';
import * as d3 from 'd3';

interface Node {
  id: string;
  name: string;
  type: string;
  x?: number;
  y?: number;
}

interface Link {
  source: string;
  target: string;
  type: string;
}

interface KnowledgeGraphProps {
  nodes: Node[];
  links: Link[];
  width?: number;
  height?: number;
}

const KnowledgeGraph: React.FC<KnowledgeGraphProps> = ({
  nodes,
  links,
  width = 800,
  height = 600,
}) => {
  const svgRef = useRef<SVGSVGElement>(null);

  useEffect(() => {
    if (!svgRef.current) return;

    const svg = d3.select(svgRef.current);
    svg.selectAll("*").remove();

    const g = svg.append("g");

    // åˆ›å»ºåŠ›å¯¼å‘å›¾
    const simulation = d3.forceSimulation(nodes)
      .force("link", d3.forceLink(links).id((d: any) => d.id))
      .force("charge", d3.forceManyBody().strength(-300))
      .force("center", d3.forceCenter(width / 2, height / 2));

    // ç»˜åˆ¶è¿æ¥çº¿
    const link = g.append("g")
      .selectAll("line")
      .data(links)
      .enter().append("line")
      .attr("stroke", "#999")
      .attr("stroke-opacity", 0.6)
      .attr("stroke-width", 2);

    // ç»˜åˆ¶èŠ‚ç‚¹
    const node = g.append("g")
      .selectAll("circle")
      .data(nodes)
      .enter().append("circle")
      .attr("r", 8)
      .attr("fill", (d) => {
        const colors = {
          concept: "#1976d2",
          technology: "#dc004e",
          protocol: "#388e3c",
          application: "#f57c00",
        };
        return colors[d.type as keyof typeof colors] || "#999";
      })
      .call(d3.drag()
        .on("start", dragstarted)
        .on("drag", dragged)
        .on("end", dragended));

    // æ·»åŠ èŠ‚ç‚¹æ ‡ç­¾
    const label = g.append("g")
      .selectAll("text")
      .data(nodes)
      .enter().append("text")
      .text((d) => d.name)
      .attr("font-size", "12px")
      .attr("fill", "#fff")
      .attr("text-anchor", "middle")
      .attr("dy", "0.35em");

    // æ›´æ–°ä½ç½®
    simulation.on("tick", () => {
      link
        .attr("x1", (d: any) => d.source.x)
        .attr("y1", (d: any) => d.source.y)
        .attr("x2", (d: any) => d.target.x)
        .attr("y2", (d: any) => d.target.y);

      node
        .attr("cx", (d: any) => d.x)
        .attr("cy", (d: any) => d.y);

      label
        .attr("x", (d: any) => d.x)
        .attr("y", (d: any) => d.y);
    });

    function dragstarted(event: any, d: any) {
      if (!event.active) simulation.alphaTarget(0.3).restart();
      d.fx = d.x;
      d.fy = d.y;
    }

    function dragged(event: any, d: any) {
      d.fx = event.x;
      d.fy = event.y;
    }

    function dragended(event: any, d: any) {
      if (!event.active) simulation.alphaTarget(0);
      d.fx = null;
      d.fy = null;
    }

    return () => {
      simulation.stop();
    };
  }, [nodes, links, width, height]);

  return (
    <svg
      ref={svgRef}
      width={width}
      height={height}
      style={{ border: "1px solid #333" }}
    />
  );
};

export default KnowledgeGraph;
```

## 6. éƒ¨ç½²è„šæœ¬ / Deployment Scripts

### 6.1 Dockeréƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# Dockeréƒ¨ç½²è„šæœ¬
# Docker Deployment Script

echo "ğŸ³ å¼€å§‹Dockeréƒ¨ç½²..."
echo "ğŸ³ Starting Docker deployment..."

# æ„å»ºåç«¯é•œåƒ
echo "ğŸ”§ æ„å»ºåç«¯é•œåƒ..."
docker build -t web3-semantics-api:latest ./backend

# æ„å»ºå‰ç«¯é•œåƒ
echo "ğŸ”§ æ„å»ºå‰ç«¯é•œåƒ..."
docker build -t web3-semantics-ui:latest ./frontend

# å¯åŠ¨æœåŠ¡
echo "ğŸš€ å¯åŠ¨æœåŠ¡..."
docker-compose up -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose ps

# è¿è¡Œæ•°æ®åº“è¿ç§»
echo "ğŸ—„ï¸ è¿è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose exec backend cargo run --bin migrate

echo "âœ… Dockeréƒ¨ç½²å®Œæˆ"
echo "âœ… Docker deployment completed"
```

### 6.2 Kuberneteséƒ¨ç½²è„šæœ¬

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web3-semantics-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web3-semantics-api
  template:
    metadata:
      labels:
        app: web3-semantics-api
    spec:
      containers:
      - name: api
        image: web3-semantics-api:latest
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: web3-semantics-secrets
              key: database-url
        - name: ELASTICSEARCH_URL
          value: "http://elasticsearch:9200"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: web3-semantics-api-service
spec:
  selector:
    app: web3-semantics-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: LoadBalancer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web3-semantics-ui
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web3-semantics-ui
  template:
    metadata:
      labels:
        app: web3-semantics-ui
    spec:
      containers:
      - name: ui
        image: web3-semantics-ui:latest
        ports:
        - containerPort: 3000
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
apiVersion: v1
kind: Service
metadata:
  name: web3-semantics-ui-service
spec:
  selector:
    app: web3-semantics-ui
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: LoadBalancer
```

## 7. ç›‘æ§å’Œæ—¥å¿—è„šæœ¬ / Monitoring and Logging Scripts

### 7.1 Prometheusç›‘æ§é…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'web3-semantics-api'
    static_configs:
      - targets: ['web3-semantics-api:8080']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']

  - job_name: 'elasticsearch'
    static_configs:
      - targets: ['elasticsearch:9200']
```

### 7.2 Grafanaä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "title": "Web3 Semantics Platform Dashboard",
    "panels": [
      {
        "title": "API Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Database Connections",
        "type": "graph",
        "targets": [
          {
            "expr": "pg_stat_database_numbackends",
            "legendFormat": "{{datname}}"
          }
        ]
      },
      {
        "title": "Cache Hit Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(redis_keyspace_hits_total[5m]) / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m])) * 100"
          }
        ]
      }
    ]
  }
}
```

## 8. æ€»ç»“ / Summary

æœ¬å®æ–½è„šæœ¬æä¾›äº†å®Œæ•´çš„Web3è¯­ä¹‰çŸ¥è¯†ç³»ç»ŸæŠ€æœ¯å¹³å°å¼€å‘å·¥å…·ï¼ŒåŒ…æ‹¬ï¼š

1. **ç¯å¢ƒæ­å»ºè„šæœ¬**: è‡ªåŠ¨åŒ–å¼€å‘ç¯å¢ƒé…ç½®
2. **æ ¸å¿ƒæœåŠ¡å®ç°**: ç”¨æˆ·ã€å†…å®¹ã€æœç´¢æœåŠ¡
3. **æ•°æ®åº“åˆå§‹åŒ–**: PostgreSQLå’ŒRedisé…ç½®
4. **APIè·¯ç”±é…ç½®**: RESTful APIå®ç°
5. **å‰ç«¯ç»„ä»¶**: Reactç»„ä»¶å’Œå¯è§†åŒ–
6. **éƒ¨ç½²è„šæœ¬**: Dockerå’ŒKuberneteséƒ¨ç½²
7. **ç›‘æ§é…ç½®**: Prometheuså’ŒGrafana

These implementation scripts provide complete development tools for the Web3 semantics knowledge system technical platform, including:

1. **Environment Setup Scripts**: Automated development environment configuration
2. **Core Service Implementation**: User, content, search services
3. **Database Initialization**: PostgreSQL and Redis configuration
4. **API Route Configuration**: RESTful API implementation
5. **Frontend Components**: React components and visualization
6. **Deployment Scripts**: Docker and Kubernetes deployment
7. **Monitoring Configuration**: Prometheus and Grafana

é€šè¿‡è¿™äº›è„šæœ¬ï¼Œæˆ‘ä»¬å¯ä»¥å¿«é€Ÿå¯åŠ¨å’Œæ¨è¿›Web3è¯­ä¹‰çŸ¥è¯†ç³»ç»ŸæŠ€æœ¯å¹³å°çš„å¼€å‘å·¥ä½œã€‚

Through these scripts, we can quickly start and advance the development work of the Web3 semantics knowledge system technical platform.
