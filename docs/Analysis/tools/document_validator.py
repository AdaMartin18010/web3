#!/usr/bin/env python3
"""
Web3æ–‡æ¡£è´¨é‡éªŒè¯å·¥å…·
è‡ªåŠ¨æ£€æŸ¥æ–‡æ¡£çš„æ•°å­¦å†…å®¹ã€ä»£ç å®žçŽ°å’Œå®‰å…¨æ€§åˆ†æž
"""

import os
import re
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import argparse

@dataclass
class ValidationResult:
    """éªŒè¯ç»“æžœæ•°æ®ç»“æž„"""
    file_path: str
    mathematical_content: bool
    code_implementation: bool
    security_analysis: bool
    academic_format: bool
    total_score: int
    issues: List[str]
    recommendations: List[str]

class DocumentValidator:
    """æ–‡æ¡£è´¨é‡éªŒè¯å™¨"""
    
    def __init__(self, base_dir: str):
        self.base_dir = Path(base_dir)
        self.results: List[ValidationResult] = []
        
        # æ•°å­¦å†…å®¹æ£€æµ‹æ¨¡å¼
        self.math_patterns = {
            'latex_formula': r'\\\w+{.*?}|\\[a-zA-Z]+|\\[a-zA-Z]+\{.*?\}',
            'math_definition': r'\\begin\{definition\}|\\begin\{theorem\}|\\begin\{proof\}',
            'math_symbols': r'\$.*?\$|\$\$.*?\$\$',
            'mathematical_notation': r'\\mathbb\{[A-Z]\}|\\mathcal\{[A-Z]\}|\\mathfrak\{[A-Z]\}'
        }
        
        # ä»£ç å®žçŽ°æ£€æµ‹æ¨¡å¼
        self.code_patterns = {
            'rust_code': r'```rust\s*\n.*?\n```',
            'typescript_code': r'```typescript\s*\n.*?\n```',
            'python_code': r'```python\s*\n.*?\n```',
            'solidity_code': r'```solidity\s*\n.*?\n```',
            'pseudocode': r'```pseudocode\s*\n.*?\n```'
        }
        
        # å®‰å…¨æ€§åˆ†æžæ£€æµ‹æ¨¡å¼
        self.security_patterns = {
            'threat_model': r'å¨èƒæ¨¡åž‹|threat model|æ”»å‡»å‘é‡|attack vector',
            'security_analysis': r'å®‰å…¨æ€§åˆ†æž|security analysis|å®‰å…¨è¯æ˜Ž|security proof',
            'vulnerability': r'æ¼æ´ž|vulnerability|æ”»å‡»|attack|é˜²æŠ¤|protection',
            'risk_assessment': r'é£Žé™©è¯„ä¼°|risk assessment|å¨èƒè¯„ä¼°|threat assessment'
        }
        
        # å­¦æœ¯æ ¼å¼æ£€æµ‹æ¨¡å¼
        self.academic_patterns = {
            'abstract': r'## ðŸ“ æ‘˜è¦|## æ‘˜è¦|## Abstract',
            'introduction': r'## 1\. å¼•è¨€|## 1\. Introduction|## 1\. ç†è®ºåŸºç¡€',
            'conclusion': r'## ç»“è®º|## Conclusion|## 6\. ç»“è®ºä¸Žå±•æœ›',
            'references': r'## å‚è€ƒæ–‡çŒ®|## References|## 7\. å‚è€ƒæ–‡çŒ®',
            'mathematical_content': r'## .*æ•°å­¦|## .*ç†è®º|## .*ç®—æ³•'
        }
    
    def validate_mathematical_content(self, content: str) -> Tuple[bool, List[str]]:
        """éªŒè¯æ–‡æ¡£æ˜¯å¦åŒ…å«æ•°å­¦å†…å®¹"""
        issues = []
        score = 0
        max_score = 40
        
        # æ£€æŸ¥LaTeXå…¬å¼
        latex_count = len(re.findall(self.math_patterns['latex_formula'], content, re.DOTALL))
        if latex_count >= 5:
            score += 10
        elif latex_count >= 2:
            score += 5
        else:
            issues.append("ç¼ºå°‘LaTeXæ•°å­¦å…¬å¼")
        
        # æ£€æŸ¥æ•°å­¦å®šä¹‰å’Œå®šç†
        definition_count = len(re.findall(self.math_patterns['math_definition'], content, re.DOTALL))
        if definition_count >= 3:
            score += 10
        elif definition_count >= 1:
            score += 5
        else:
            issues.append("ç¼ºå°‘æ•°å­¦å®šä¹‰å’Œå®šç†")
        
        # æ£€æŸ¥æ•°å­¦ç¬¦å·
        symbol_count = len(re.findall(self.math_patterns['math_symbols'], content, re.DOTALL))
        if symbol_count >= 10:
            score += 10
        elif symbol_count >= 5:
            score += 5
        else:
            issues.append("ç¼ºå°‘æ•°å­¦ç¬¦å·è¡¨ç¤º")
        
        # æ£€æŸ¥æ•°å­¦è®°å·
        notation_count = len(re.findall(self.math_patterns['mathematical_notation'], content, re.DOTALL))
        if notation_count >= 3:
            score += 10
        elif notation_count >= 1:
            score += 5
        else:
            issues.append("ç¼ºå°‘æ•°å­¦è®°å·")
        
        return score >= 20, issues
    
    def validate_code_implementation(self, content: str) -> Tuple[bool, List[str]]:
        """éªŒè¯æ–‡æ¡£æ˜¯å¦åŒ…å«ä»£ç å®žçŽ°"""
        issues = []
        score = 0
        max_score = 30
        
        # æ£€æŸ¥Rustä»£ç 
        rust_code = re.findall(self.code_patterns['rust_code'], content, re.DOTALL)
        if rust_code:
            score += 10
            # æ£€æŸ¥ä»£ç è´¨é‡
            for code in rust_code:
                if 'pub fn' in code or 'impl' in code:
                    score += 5
                    break
        else:
            issues.append("ç¼ºå°‘Rustä»£ç å®žçŽ°")
        
        # æ£€æŸ¥TypeScriptä»£ç 
        ts_code = re.findall(self.code_patterns['typescript_code'], content, re.DOTALL)
        if ts_code:
            score += 5
        else:
            issues.append("ç¼ºå°‘TypeScriptä»£ç å®žçŽ°")
        
        # æ£€æŸ¥ä¼ªä»£ç 
        pseudo_code = re.findall(self.code_patterns['pseudocode'], content, re.DOTALL)
        if pseudo_code:
            score += 5
        else:
            issues.append("ç¼ºå°‘ç®—æ³•ä¼ªä»£ç ")
        
        # æ£€æŸ¥ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£
        if '///' in content or '//!' in content or '/*' in content:
            score += 5
        else:
            issues.append("ä»£ç ç¼ºå°‘æ³¨é‡Šå’Œæ–‡æ¡£")
        
        return score >= 15, issues
    
    def validate_security_analysis(self, content: str) -> Tuple[bool, List[str]]:
        """éªŒè¯æ–‡æ¡£æ˜¯å¦åŒ…å«å®‰å…¨åˆ†æž"""
        issues = []
        score = 0
        max_score = 20
        
        # æ£€æŸ¥å¨èƒæ¨¡åž‹
        if re.search(self.security_patterns['threat_model'], content, re.IGNORECASE):
            score += 5
        else:
            issues.append("ç¼ºå°‘å¨èƒæ¨¡åž‹")
        
        # æ£€æŸ¥å®‰å…¨æ€§åˆ†æž
        if re.search(self.security_patterns['security_analysis'], content, re.IGNORECASE):
            score += 5
        else:
            issues.append("ç¼ºå°‘å®‰å…¨æ€§åˆ†æž")
        
        # æ£€æŸ¥æ¼æ´žåˆ†æž
        if re.search(self.security_patterns['vulnerability'], content, re.IGNORECASE):
            score += 5
        else:
            issues.append("ç¼ºå°‘æ¼æ´žåˆ†æž")
        
        # æ£€æŸ¥é£Žé™©è¯„ä¼°
        if re.search(self.security_patterns['risk_assessment'], content, re.IGNORECASE):
            score += 5
        else:
            issues.append("ç¼ºå°‘é£Žé™©è¯„ä¼°")
        
        return score >= 10, issues
    
    def validate_academic_format(self, content: str) -> Tuple[bool, List[str]]:
        """éªŒè¯æ–‡æ¡£æ˜¯å¦ç¬¦åˆå­¦æœ¯æ ¼å¼"""
        issues = []
        score = 0
        max_score = 10
        
        # æ£€æŸ¥æ‘˜è¦
        if re.search(self.academic_patterns['abstract'], content, re.IGNORECASE):
            score += 2
        else:
            issues.append("ç¼ºå°‘æ‘˜è¦éƒ¨åˆ†")
        
        # æ£€æŸ¥å¼•è¨€
        if re.search(self.academic_patterns['introduction'], content, re.IGNORECASE):
            score += 2
        else:
            issues.append("ç¼ºå°‘å¼•è¨€éƒ¨åˆ†")
        
        # æ£€æŸ¥ç»“è®º
        if re.search(self.academic_patterns['conclusion'], content, re.IGNORECASE):
            score += 2
        else:
            issues.append("ç¼ºå°‘ç»“è®ºéƒ¨åˆ†")
        
        # æ£€æŸ¥å‚è€ƒæ–‡çŒ®
        if re.search(self.academic_patterns['references'], content, re.IGNORECASE):
            score += 2
        else:
            issues.append("ç¼ºå°‘å‚è€ƒæ–‡çŒ®")
        
        # æ£€æŸ¥æ•°å­¦å†…å®¹ç»“æž„
        if re.search(self.academic_patterns['mathematical_content'], content, re.IGNORECASE):
            score += 2
        else:
            issues.append("ç¼ºå°‘æ•°å­¦å†…å®¹ç»“æž„")
        
        return score >= 5, issues
    
    def generate_recommendations(self, issues: List[str]) -> List[str]:
        """æ ¹æ®é—®é¢˜ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        for issue in issues:
            if "ç¼ºå°‘LaTeXæ•°å­¦å…¬å¼" in issue:
                recommendations.append("æ·»åŠ LaTeXæ•°å­¦å…¬å¼ï¼Œä½¿ç”¨\\begin{equation}çŽ¯å¢ƒ")
            elif "ç¼ºå°‘æ•°å­¦å®šä¹‰å’Œå®šç†" in issue:
                recommendations.append("æ·»åŠ æ•°å­¦å®šä¹‰å’Œå®šç†ï¼Œä½¿ç”¨\\begin{definition}å’Œ\\begin{theorem}çŽ¯å¢ƒ")
            elif "ç¼ºå°‘Rustä»£ç å®žçŽ°" in issue:
                recommendations.append("æ·»åŠ Rustä»£ç å®žçŽ°ï¼ŒåŒ…å«å®Œæ•´çš„ç»“æž„å®šä¹‰å’Œæ–¹æ³•å®žçŽ°")
            elif "ç¼ºå°‘å¨èƒæ¨¡åž‹" in issue:
                recommendations.append("æ·»åŠ å¨èƒæ¨¡åž‹ï¼Œæ˜Žç¡®æ”»å‡»è€…èƒ½åŠ›å’Œæ”»å‡»ç›®æ ‡")
            elif "ç¼ºå°‘å®‰å…¨æ€§åˆ†æž" in issue:
                recommendations.append("æ·»åŠ å®‰å…¨æ€§åˆ†æžï¼ŒåŒ…æ‹¬æ”»å‡»å‘é‡å’Œé˜²æŠ¤æŽªæ–½")
            elif "ç¼ºå°‘æ‘˜è¦éƒ¨åˆ†" in issue:
                recommendations.append("æ·»åŠ æ‘˜è¦éƒ¨åˆ†ï¼Œç®€è¦è¯´æ˜Žç ”ç©¶å†…å®¹å’Œè´¡çŒ®")
            elif "ç¼ºå°‘å‚è€ƒæ–‡çŒ®" in issue:
                recommendations.append("æ·»åŠ å‚è€ƒæ–‡çŒ®ï¼Œéµå¾ªå­¦æœ¯å¼•ç”¨è§„èŒƒ")
        
        return recommendations
    
    def validate_file(self, file_path: Path) -> ValidationResult:
        """éªŒè¯å•ä¸ªæ–‡ä»¶"""
        try:
            content = file_path.read_text(encoding='utf-8')
        except UnicodeDecodeError:
            try:
                content = file_path.read_text(encoding='gbk')
            except:
                content = ""
        
        # æ‰§è¡Œå„é¡¹éªŒè¯
        math_valid, math_issues = self.validate_mathematical_content(content)
        code_valid, code_issues = self.validate_code_implementation(content)
        security_valid, security_issues = self.validate_security_analysis(content)
        academic_valid, academic_issues = self.validate_academic_format(content)
        
        # åˆå¹¶æ‰€æœ‰é—®é¢˜
        all_issues = math_issues + code_issues + security_issues + academic_issues
        
        # è®¡ç®—æ€»åˆ†
        total_score = 0
        if math_valid:
            total_score += 40
        if code_valid:
            total_score += 30
        if security_valid:
            total_score += 20
        if academic_valid:
            total_score += 10
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        recommendations = self.generate_recommendations(all_issues)
        
        return ValidationResult(
            file_path=str(file_path),
            mathematical_content=math_valid,
            code_implementation=code_valid,
            security_analysis=security_valid,
            academic_format=academic_valid,
            total_score=total_score,
            issues=all_issues,
            recommendations=recommendations
        )
    
    def validate_directory(self) -> Dict:
        """éªŒè¯æ•´ä¸ªç›®å½•"""
        print(f"å¼€å§‹éªŒè¯ç›®å½•: {self.base_dir}")
        
        markdown_files = list(self.base_dir.rglob('*.md'))
        print(f"æ‰¾åˆ° {len(markdown_files)} ä¸ªMarkdownæ–‡ä»¶")
        
        for file_path in markdown_files:
            if file_path.name.startswith('.'):
                continue
            
            print(f"éªŒè¯æ–‡ä»¶: {file_path.name}")
            result = self.validate_file(file_path)
            self.results.append(result)
        
        return self.generate_summary()
    
    def generate_summary(self) -> Dict:
        """ç”ŸæˆéªŒè¯æ‘˜è¦"""
        total_files = len(self.results)
        if total_files == 0:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°å¯éªŒè¯çš„æ–‡ä»¶"}
        
        # ç»Ÿè®¡å„é¡¹æŒ‡æ ‡
        math_count = sum(1 for r in self.results if r.mathematical_content)
        code_count = sum(1 for r in self.results if r.code_implementation)
        security_count = sum(1 for r in self.results if r.security_analysis)
        academic_count = sum(1 for r in self.results if r.academic_format)
        
        # è®¡ç®—å¹³å‡åˆ†
        avg_score = sum(r.total_score for r in self.results) / total_files
        
        # è´¨é‡åˆ†å¸ƒ
        excellent = sum(1 for r in self.results if r.total_score >= 90)
        good = sum(1 for r in self.results if 80 <= r.total_score < 90)
        fair = sum(1 for r in self.results if 70 <= r.total_score < 80)
        poor = sum(1 for r in self.results if r.total_score < 70)
        
        summary = {
            "validation_date": datetime.now().isoformat(),
            "total_files": total_files,
            "quality_distribution": {
                "excellent": excellent,
                "good": good,
                "fair": fair,
                "poor": poor
            },
            "component_scores": {
                "mathematical_content": f"{math_count}/{total_files} ({math_count/total_files*100:.1f}%)",
                "code_implementation": f"{code_count}/{total_files} ({code_count/total_files*100:.1f}%)",
                "security_analysis": f"{security_count}/{total_files} ({security_count/total_files*100:.1f}%)",
                "academic_format": f"{academic_count}/{total_files} ({academic_count/total_files*100:.1f}%)"
            },
            "average_score": round(avg_score, 1),
            "files_need_improvement": [r.file_path for r in self.results if r.total_score < 70],
            "top_files": sorted(self.results, key=lambda x: x.total_score, reverse=True)[:5]
        }
        
        return summary
    
    def save_results(self, output_file: str):
        """ä¿å­˜éªŒè¯ç»“æžœ"""
        summary = self.generate_summary()
        
        # å‡†å¤‡è¯¦ç»†ç»“æžœ
        detailed_results = []
        for result in self.results:
            detailed_results.append({
                "file_path": result.file_path,
                "mathematical_content": result.mathematical_content,
                "code_implementation": result.code_implementation,
                "security_analysis": result.security_analysis,
                "academic_format": result.academic_format,
                "total_score": result.total_score,
                "issues": result.issues,
                "recommendations": result.recommendations
            })
        
        output_data = {
            "summary": summary,
            "detailed_results": detailed_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"éªŒè¯ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
    
    def print_summary(self):
        """æ‰“å°éªŒè¯æ‘˜è¦"""
        summary = self.generate_summary()
        
        print("\n" + "="*60)
        print("Web3æ–‡æ¡£è´¨é‡éªŒè¯æŠ¥å‘Š")
        print("="*60)
        print(f"éªŒè¯æ—¶é—´: {summary['validation_date']}")
        print(f"æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        print(f"å¹³å‡è´¨é‡åˆ†æ•°: {summary['average_score']}/100")
        
        print("\nè´¨é‡åˆ†å¸ƒ:")
        dist = summary['quality_distribution']
        print(f"  ä¼˜ç§€ (90-100åˆ†): {dist['excellent']} ä¸ªæ–‡ä»¶")
        print(f"  è‰¯å¥½ (80-89åˆ†): {dist['good']} ä¸ªæ–‡ä»¶")
        print(f"  åˆæ ¼ (70-79åˆ†): {dist['fair']} ä¸ªæ–‡ä»¶")
        print(f"  ä¸åˆæ ¼ (<70åˆ†): {dist['poor']} ä¸ªæ–‡ä»¶")
        
        print("\nç»„ä»¶å¾—åˆ†:")
        for component, score in summary['component_scores'].items():
            print(f"  {component}: {score}")
        
        if summary['files_need_improvement']:
            print(f"\néœ€è¦æ”¹è¿›çš„æ–‡ä»¶ ({len(summary['files_need_improvement'])} ä¸ª):")
            for file_path in summary['files_need_improvement'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  - {file_path}")
        
        print("\nè´¨é‡æœ€é«˜çš„æ–‡ä»¶:")
        for i, result in enumerate(summary['top_files'], 1):
            print(f"  {i}. {Path(result.file_path).name} ({result.total_score}/100)")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Web3æ–‡æ¡£è´¨é‡éªŒè¯å·¥å…·')
    parser.add_argument('directory', help='è¦éªŒè¯çš„ç›®å½•è·¯å¾„')
    parser.add_argument('-o', '--output', default='validation_results.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.directory):
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {args.directory}")
        return
    
    validator = DocumentValidator(args.directory)
    validator.validate_directory()
    validator.save_results(args.output)
    validator.print_summary()

if __name__ == "__main__":
    main()
